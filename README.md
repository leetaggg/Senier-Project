# 마스크 얼굴인식
<h2>1.개발 배경</h2>
2019년 코로나19 바이러스의 확산으로 세계적으로 팬데믹 유행했으며 우리나라 또한, 코로나 확산을 피해 갈 수 없었다. 우리나라는 특정 인원수 이상 집합 금지, 마스크 의무 착용, 특정 시간 이후 영업 금지 등의 사회적 거리 두기를 시행하여 사람 간의 접촉을 통제했고, 이는 우리 사회에 큰 영향을 미쳤다. 그중 마스크 의무 착용은 우리가 생활하는데 많은 불편함을 불러왔다. 그중 마스크 의무 착용은 신체적으로도 불편할 뿐만 아니라 얼굴이 사용되는 상황에서도 불편함을 준다. 현재 IT 기기는 사용자 인증 수단으로 생체 인증 수단을 많이 사용한다. 생체 인증 수단으로는 안면과 지문이 가장 많이 사용되는데, 안면을 활용한 인증은 대부분 마스크를 착용한 상태에서는 인식이 잘되지 않거나 불가능하다. 이러한 상황을 해결하기 위해서 사용자들은 잠시 마스크를 벗고 인증하는데, 이는 임시방편일뿐더러 질병 확산의 위험이 있다.
본 프로젝트는 마스크를 착용한 상태에서도 얼굴 인식이 가능하여 불편함을 해결하였고, 이 얼굴 인식을 일상생활에서 흔히 하는 출석 확인에 적용하여 편의성을 제공한다. 또한 생체 인식 기술들은 보편성, 유일성의 특징을 가지고 있어 모든 사람이 쉽게 사용할 수 있으며, 다른 사람이 대신 인증해 주는 대리 출석을 방지해 줄 수 있을 것으로 기대된다.
<h2>2.마스크 착용 시 얼굴 인식의 필요성</h2>
코로나19 바이러스의 발생 이후 한동안 마스크의 착용은 의무화가 되었지만, 현재는 의무 착용화가 폐지된 상태이다. 하지만 이후에도 코로나19와 같은 팬데믹이 유행할 수 있고, 그때에도 지금과 같이 대처를 할 것이다. 대부분의 얼굴인식은 마스크를 착용한 상태에서는 불가능하다.
<h2>3.타 기업들의 얼굴인식 기술</h2>
FaceID는 애플의 인증 수단으로 2017년도부터 사용된 얼굴인식 기술이다. 
FaceID는 깊이 측정 카메라인 TrueDepth 카메라를 사용하여 수천 개의 보이지 않는 점을 투사하고 분석하여 정확한 얼굴 데이터를 수집한다. 이를 통해 얼굴의 심도 맵을 만들고 얼굴의 적외선 이미지도 촬영한다. 
3D이미지 및 적외선 센서 업체 트라이나믹스(TrinamixX)는 레이저 기반의 도트 프로젝터 모듈을 이용해 보이지 않는 근적외선을 발산하여 얼굴을 일정한 도트 패턴으로 식별한다. 피부에 근적외선을 비추면 색소나 가시광에 영향을 받지 않는 후방산란 패턴이 성형된다는 점을 이용한 기술로, 각 광점 반사는 기기 내 CMOS 카메라로 포착해 빔 프로파일로 분석한다.
<h2>4.제안한 프로젝트 기술</h2>
본 프로젝트에서는 얼굴인식의 한계를 해결한 마스크 얼굴인식을 제안한다. 제안한 프로젝트는 마스크를 착용한 상태에서도 얼굴인식이 가능하며 해당 기술을 생체인증 수단으로 활용하여 출석 확인 시스템을 구축하였다. 이 시스템은 열 화상 카메라로 체온 측정이 가능하고 어플을 통하여 회원가입, 사진등록, 출석 여부 확인, 회원 탈퇴를 할 수 있도록 하였다. 이 프로젝트는 마스크를 착용한 상태에서 얼굴인식을 함으로써 비말 차단의 효과와 얼굴인식이라는 생체 인증 수단으로 대리 출석을 방지하는 효과가 있으며 체온 측정을 통해 발열 환자를 사전에 인지하여 접근을 통제할 수 있다. 또한 대부분의 얼굴 인식하여 체온을 측정하는 장비는 최소 1,000,000원 이상의 고가이지만, 해당 프로젝트는 비교적 적은 비용으로 구현이 가능하다는 장점이 있다.
<h2>5.얼굴 검출</h2>
딥 러닝을 활용한 객체 검출(Object Detection)은 정해진 위치와 정해진 크기의 객체만 찾는 단일 단계 방식(Single-Stage Methods)과 영역 제안(Region Proposal)을 하는 이단계 방식(Two-Stage Methods)이 있다. 단일 단계 방식은 정확도가 보다 떨어지지만 빠른 처리가 가능하고, 이단계 방식은 높은 정확도를 제공하지만 처리 속도가 느리다. 얼굴 검출은 단일 단계 방식으로도 충분한 정확도를 얻을 수 있고, 본 프로젝트는 실시간 영상 처리가 필요하기 때문에 단일 단계 방식으로 선택하였으며, 그 중 multi-task learning을 비롯한 여러 기술을 적극적으로 도입하여 성능을 높인 one-stage SOTA 얼굴 검출 모델인 Retinaface 모델을 사용했다. Retinaface는 5개의 facial landmarks와 3D position and correspondence of each facial pixel을 multi-task로 학습하는 방식으로 사용하였고, 가벼운 backbone 구조를 채용하여 VGA 해상도 이미지에서 싱글 CPU로 실시간 성능을 낼 수 있다. 또한  WIDER FACE의 데이터셋에서 two-stage model을 사용하는 방법보다 1.1% 높게 측정되었다.
<h2>6.얼굴 인식</h2>
검출된 얼굴을 인지하기 위해서는 사용자의 얼굴을 학습시켜 해당 사용자의 얼굴을 인식하는 방법과 사용자의 얼굴과 저장된 여러 사용자들의 얼굴 사진들을 비교하여 유사도가 가장 높은 사용자의 얼굴을 선택하는 방법이 있다. 사용자의 얼굴을 학습하는 방법이 정확도가 더 높지만, 새로운 사용자가 추가된다면 해당 사용자의 얼굴을 포함하여 다시 학습 해야하기 때문에 상당한 시간이 소요된다. 새로운 사용자가 자주 추가되는 본 프로젝트는 후자의 방법을 선택하였다. 얼굴인식은 ArcFace모델을 사용하였다. 얼굴 인식 모델의 분별력을 추가로 향상 시키기 위한 Additive Angular Margin Loss(ArcFace)는 DCNN Feature와 마지막 완전 연결 계층 사이의 내적은 정규화 후의 Feature와 Weight의 코사인 거리와 동일하고, 호-코사인(arc-cosine)함수를 사용하여 현재 Feature와 목표 가중치 사이의 각도를 계산한다. 나중에 목표 각도에 Additive Angular Margin을 추가하고, 코사인함수를 이용하여 목표 로짓(Logit)을 다시 얻는다. 그런 다음 우리는 모든 로짓들을 고정된 Feature Norm에 따라 re-scale하고, 후속 단계들은 Softmax Loss와 동일하게 동작한다. 이로 인해 얻을 수 있는 장점은 정규화된 Hypersphere에서 호(Arc)와 각도(Angle)사이의 정확한 일치성 덕분에 직접 Geodesic Distance Margin을 최적화했다. Features와 Weights 사이의 각도 통계량 분석을 통해 512차원 공간에서 일어나는 일은 직관적으로 설명할 수 있다. 이런 특징으로 ArcFace는 대규모 영상 데이터셋을 포함한 여러 얼굴 인식에서 준수한 성능을 보여준다. ArcFace를 이용하여 매칭을 진행할 때 사진을 의 목표 공간으로 임베딩한다. 임베딩하여 생성된 두 벡터 사이의 거리를 Angular Cosine Distance로 측정하여 가장 가까운 두 사진을 매칭하는 알고리즘이다. 이 때 임베딩한 데이터를 피클 파일로 저장하여 사용자의 등록과 삭제를 도와준다. 검출된 얼굴이 마스크를 착용하고 있어 얼굴의 하단부가 가려지는 폐색 문제를 해결하기 위해서 출석부의 사진과 탐지된 얼굴의 동일성을 판단하기 위해서 처음 임베딩을 할 때 RetinaFace에서 검출된 바운딩 박스에서 코를 지나는 수평선 하단부를 모두 흰색으로 바꾸어 새로운 이미지를 생성한다. 상단부에서만 다른 특성을 추출하여 상단부 위주의 거리를 측정하여 임베딩하는 방식을 사용하여 마스크를 쓰고 있어도 얼굴 인식이 가능하도록 알고리즘을 구현했다. 얼굴을 매칭하여 얻어낸 유사도값을 10위까지 순위를 정한뒤, 가장 높은 순위와 분포도가 높은 사용자를 선택해서 알고리즘의 정확도를 높였다.
<h2>7.출석</h2>
얼굴을 인식후 출석 확인 및 정보를 입력하기 위해서는 해당 사용자의 개인 정보가 필요하다.
<p align="center"><img src="https://user-images.githubusercontent.com/57284689/199149965-c3c9a5e7-1ec3-4c66-9a6a-d75b66b9c918.png" width = 250 height = 250></p>
회원가입을 통해 사용자들의 개인 정보를 데이터베이스에 저장한 뒤 사용자의 사진을 5장 찍어 PC 내부에 저장한다. 업로드한 회원 정보를 저장하는 데이터베이스는 My-SQL을 사용하였다. MySQL은 가장 널리 사용되고 있는 관계형 데이터베이스 시스템으로 PHP와 함께 사용되어 안드로이드에서도 활용이 가능하다. 데이터베이스는 회원 정보 테이블과 출석 명단 테이블이 있다. 회원 정보 테이블에는 학번, 비밀번호, 이름, 학년의 회원 정보 컬럼과 안드로이드에서의 로그인을 제어하는 갱신 컬럼이 있고, 출석 명단 테이블에는 사용자들의 출석 정보를 담는 컬럼이 있다.
회원가입 완료 후 출석 확인 시 얼굴이 인식되면 얼굴 근처로 빨간색 박스가 뜨면서 사용자의 얼굴을 검출하여 검출된 학번을 출력하고, 검출된 얼굴의 좌표값은 사용자의 체온 측정을 위해 라즈베리 파이로 전송된다.
<p align="center">
<img src=https://user-images.githubusercontent.com/57284689/199151016-aca88649-47c2-4dc0-8963-c6783e783333.png width = 250 height = 250>
</p>
체온을 측정할 때 필요한 열화상 카메라는 mcu기반 모듈인 mlx9060을 사용하였으며, PC와의 통신을 위해 라즈베리 파이를 사용하였다. PC에서 검출된 사용자의 얼굴 좌표 값을 열 화상 카메라의 해상도에 맞는 크기로 resize하여 박스를 생성하고, 그 박스 내부의 온도를 측정하여 TCP/IP 통신을 통해 PC로 전송된다. 얼굴을 인식하고 체온이 37.5℃ 이하일 때 출석하기 버튼을 누르면 데이터베이스의 출석 정보를 수정하고, 출석 현황을 보여준다. 출석하기 버튼을 누를 때 마다 얼굴인식이 성공한 것으로 간주하여 얼굴 사진을 새롭게 추가하여 정확도를 높인다.
<div align ="center">
<img src=https://user-images.githubusercontent.com/57284689/199151263-e498ee4e-9add-41ca-86c0-b4bb3a0644ee.png width = 250 height = 250>
<img src=https://user-images.githubusercontent.com/57284689/199151273-41d16ee0-2617-40c5-a153-e3262abe50f5.png width = 250 height = 250>
</div>
<h2>8.회원 탈퇴</h2>
더 이상 출석 체크를 할 필요가 없을 때 회원 탈퇴를 하여 데이터베이스의 개인정보와 PC에 올라가있는 사진들 그리고 임베딩 되어있는 자료들까지 모두 지울 수 있다.
<h2>9.안드로이드</h2>
안드로이드에서 데이터베이스에 접속하기 위해서는 PHP를 이용해야 한다. HTTP 웹서버인 아파치를 구축하였고 서버 내에 있는 PHP 파일에 입력된 사용자의 회원 정보를 담아 데이터베이스에 업로드 한다.
데이터베이스의 갱신 컬럼의 값에 따라 안드로이드에서 시스템 접근 상태가 정해지며, 갱신 컬럼은 안드로이드에서 대리 회원 가입을 막기 위함이다.
<p align="center">
<img src=https://user-images.githubusercontent.com/57284689/199152515-1fd79200-77f4-4200-848b-a9eb4c52c452.png width = 250 height = 350>
</p>
최초 회원 가입 후 갱신 값은 0이며, 로그인 시도 시 사진을 등록 해야한다. 사진 등록 시 5장의 사진을 웹 서버로 업로드하고, 업로드 후 갱신 값은 1로 변경된다. 
PC의 출석 프로그램에서는 실시간으로 스레드 실행하여 웹 서버에 업로드 되어있는 사진을 다운로드하고, 그 사진들이 같은 사람의 사진인지 각 사진의 유사도를 측정한다. 유사도 측정 실패 시 갱신 값은 2로 변경되며 안드로이드에서는 다시 사진을 등록해야하고, 성공 시 해당 사진을 임베딩하여 피클 파일에 추가하고, 갱신 값은 3으로 변경되며 안드로이드에서 로그인이 가능하다. 로그인 성공 시 출석확인, 추가 사진 등록, 회원 탈퇴 등 3가지 기능을 사용 할 수 있다.출석 확인은 해당 회원의 출석 명단을 데이터베이스로부터 받아 리스트뷰로 사용자에게 출력해준다.
<div align ="center">
<img src=https://user-images.githubusercontent.com/57284689/199152758-2ce0cc74-433c-4abc-b50e-e4b3b0ddc448.png width = 250 height = 350>
<img src=https://user-images.githubusercontent.com/57284689/199152762-d01d50b3-9373-499b-8734-121ec95958d0.png width = 250 height = 350>
</div>
추가 사진 등록은 사용자의 안경 착용, 머리 스타일 등이 달라지는 상황에서 추가로 사진을 등록하기 위함이며, 이는 회원가입과 마찬가지로 저장 되어있는 사용자의 사진과 유사도를 측정하여 성공 시 저장된다.
회원 탈퇴는 회원 가입 시 사용했던 비밀번호를 입력받아 확인하며, 이는 잘못 눌렀을 때를 방지하기 위한 크로스 체크이다. 회원 탈퇴 시 데이터베이스에 저장되어있는 회원 정보를 모두 삭제하고, PC에서 확인을 위해 웹 서버로 탈퇴를 시도한 회원 명단을 업로드하며, PC에서는 이를 받아 사용자의 사진과 임베딩된 피클 파일 내용을 일부분 삭제한다.
<div align ="center">
<img src=https://user-images.githubusercontent.com/57284689/199152977-5edccb90-26dc-414e-8476-c6a4be597e41.png width = 250 height = 350>
<img src=https://user-images.githubusercontent.com/57284689/199152981-9b9363ad-a352-4002-bc1f-82decfedddfe.png width = 250 height = 350>
</div>
<h2>10.업무 분담</h2>
<div align ="center">
<img src= https://user-images.githubusercontent.com/57284689/199153132-6b2e35b1-03d3-406c-b787-b3ce5edab0af.png width = 500 height = 200>
</div>
<h2>11.프로젝트 진행 차트</h2>
<div align ="center">
<img src= https://user-images.githubusercontent.com/57284689/199153323-5c91110f-c26d-4e9a-a677-b9ed76abf458.png width = 500 height = 200>
</div>
<h2>12.논문</h2>
<h2> * 참고 자료 </h2>

[1] Joseph Redmon, “You Only Look Once: Unified,Real-Ti
me Object Detection,” IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), pp. 779-788,
2016.</br>
[2] Ross Girshick, Jeff Donahue ,Trevor Darrell, Jitendra
Malik, “Rich feature hierarchies for accurate object
detection and semantic segmentation,” IEEE Conference
on Computer Vision and Pattern Recognition, pp.
580-587, 2014</br>
[3] J. Deng, J. Guo, N. Xue and S. Zafeiriou, "ArcFace: Additive Angular Margin Loss for Deep Face Recognition," 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 4685-4694, doi: 10.1109/CVPR.2019.00482.</br>
